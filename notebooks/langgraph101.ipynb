{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1fbd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n",
      "The capital of France is Paris.\n",
      "I don't have real-time weather data, but you can easily check the current weather in Tokyo by using a weather website or app. Typically, these platforms provide up-to-date information on temperature, humidity, precipitation, and forecasts. Would you like some tips on how to find this information?\n",
      "Testing calculator tool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "response = llm.invoke(\"What is the capital of France?\")\n",
    "print(response.content)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "response = llm.invoke(\"What is the capital of France?\")\n",
    "print(response.content)\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that can answer questions about the weather.\"),\n",
    "    HumanMessage(content=\"What is the weather in Tokyo?\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d037fe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing calculator tool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Calculate mathematical expressions. Allways use this for any math calculations.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"The result of the expression {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calcuating {expression}: {e}\"\n",
    "    \n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# Bind tools to the LLM\n",
    "tools = [calculator, search_tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"Testing calculator tool\")\n",
    "response = llm_with_tools.invoke(\"What is 25 * 4 + 17?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d6ee521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_1M9wj3z9Mp3aE5FjVIKhnDIr', 'function': {'arguments': '{\"expression\":\"25 * 4 + 17\"}', 'name': 'calculator'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 110, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByeiLIKEPl6pXGWqp0YM1ZyhznZvP', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8a5c5f80-4f13-4e76-bcd2-e12dacf80584-0', tool_calls=[{'name': 'calculator', 'args': {'expression': '25 * 4 + 17'}, 'id': 'call_1M9wj3z9Mp3aE5FjVIKhnDIr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 110, 'output_tokens': 20, 'total_tokens': 130, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d79aac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_map = {\n",
    "    \"calculator\": calculator,\n",
    "    \"duckduckgo_search\": DuckDuckGoSearchRun()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b01aa75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(response, tool_map):\n",
    "    \"\"\"Executes all tool calls in the LLM response using the tool map.\"\"\"\n",
    "    if not getattr(response, \"tool_calls\", None):\n",
    "        return response\n",
    "    print(f\"Tool calls requested: {len(response.tool_calls)}\")\n",
    "    for tool_call in response.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        args = tool_call[\"args\"]\n",
    "\n",
    "        print(f\"Tool: {tool_name}\")\n",
    "        print(f\"Args: {args}\")\n",
    "        \n",
    "        tool = tool_map.get(tool_name)\n",
    "        if tool:\n",
    "            result = tool.invoke(args)\n",
    "            preview = result[:200] + \"...\" if isinstance(result, str) and len(result) > 200 else result\n",
    "            print(f\"Tool result: {preview}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5819558a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is 25 * 4 + 17?\n",
      "Response: \n",
      "Tool calls requested: 1\n",
      "Tool: calculator\n",
      "Args: {'expression': '25 * 4 + 17'}\n",
      "Tool result: The result of the expression 25 * 4 + 17 is 117\n",
      "\n",
      "\n",
      "Query: Search for the latest news abount Artificial Intelligence.\n",
      "Response: \n",
      "Tool calls requested: 1\n",
      "Tool: duckduckgo_search\n",
      "Args: {'query': 'latest news about Artificial Intelligence'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Portfolio\\langgraph_exploration\\.venv\\Lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool result: Jun 25, 2025 · Artificial Intelligence News. Everything on AI including futuristic robots with artificial intelligence, computer models of human intelligence and more. A Taruma Baterias oferece bateri...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_llm_tool(query):\n",
    "    print(f\"Query: {query}\")\n",
    "    response = llm_with_tools.invoke(query)\n",
    "    print(f\"Response: {getattr(response, 'content', response)}\")\n",
    "    handle_tool_calls(response, tool_map)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "test_llm_tool(\"What is 25 * 4 + 17?\")\n",
    "test_llm_tool(\"Search for the latest news abount Artificial Intelligence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba45b4d",
   "metadata": {},
   "source": [
    "Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b649deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing structured output\n",
      "name='John Smith' age=30 occupation='software engineer' skills=['Python', 'SQL', 'machine learning']\n",
      "Name:  John Smith\n",
      "Age:  30\n",
      "Occupation:  software engineer\n",
      "Skills:  Python, SQL, machine learning\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class PersonInfo(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"The full name of the person.\")\n",
    "    age: int = Field(description=\"The age of the person.\")\n",
    "    occupation: Optional[str] = Field(description=\"The occupation of the person.\")\n",
    "    skills: List[str] = Field(description=\"The skills of the person.\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(PersonInfo)\n",
    "\n",
    "\n",
    "#Test with person info\n",
    "print(\"Testing structured output\")\n",
    "\n",
    "person_prompt = \"\"\"\n",
    "Extract information about the person:\n",
    "\"John Smith is 30 years old and works as a software engineer. He is skilled in Python, SQL, and machine learning.\"\n",
    "\"\"\"\n",
    "\n",
    "response = structured_llm.invoke(person_prompt)\n",
    "print(response)\n",
    "\n",
    "\n",
    "print(\"Name: \", response.name)\n",
    "print(\"Age: \", response.age)\n",
    "print(\"Occupation: \", response.occupation)\n",
    "print(\"Skills: \", \", \".join(response.skills))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493f753",
   "metadata": {},
   "source": [
    "Langgraph Básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14b5d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b897c8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94b69a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot node function created\n"
     ]
    }
   ],
   "source": [
    "def chatbot_node(state: State) -> State:\n",
    "    \"\"\"The main chatbot node that processes messages and generates responses.\"\"\"\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"Chatbot node function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7bffe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9988879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot_node)\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ea9c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = graph.get_graph(xray=True).draw_mermaid_png()\n",
    "with open(\"graph.png\", \"wb\") as f:\n",
    "    f.write(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15ead163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(\"graph.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "062dcf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello! My name is Leonardo?\n",
      "AI: Hello, Leonardo! How can I assist you today?\n",
      "User: Do you remember my name?\n",
      "AI: I don’t have the ability to remember personal information or previous interactions. However, I'm here to help with any questions or topics you want to discuss! What would you like to talk about?\n"
     ]
    }
   ],
   "source": [
    "def test_chatbot(message: str):\n",
    "    \"\"\"Helper function to test our chatbot.\"\"\"\n",
    "    print(f\"User: {message}\")\n",
    "\n",
    "    initial_state = {\"messages\": [HumanMessage(content=message)]}\n",
    "    result = graph.invoke(initial_state)\n",
    "\n",
    "    ai_response = result[\"messages\"][-1].content\n",
    "    print(f\"AI: {ai_response}\")\n",
    "    return result\n",
    "\n",
    "test_cases = [\n",
    "    \"Hello! My name is Leonardo?\",\n",
    "    \"Do you remember my name?\"\n",
    "]\n",
    "\n",
    "for test_message in test_cases:\n",
    "    test_chatbot(test_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea072c2f",
   "metadata": {},
   "source": [
    "Adding memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0b92919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b854d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory added to chatbot\n"
     ]
    }
   ],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "graph_with_memory = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Memory added to chatbot\")\n",
    "\n",
    "def chat_with_memory(message: str, thread_id: str):\n",
    "    \"\"\"Chat function with memory\"\"\"\n",
    "    print(f\"\\n User: {message}\")\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "    initial_state = {\"messages\": [HumanMessage(content=message)]}\n",
    "    result = graph_with_memory.invoke(initial_state, config)\n",
    "\n",
    "    ai_response = result[\"messages\"][-1].content\n",
    "    print(f\"AI: {ai_response}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d20e2845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing Conversation with Memory:\n",
      "\n",
      " User: Hello! My name is Leonardo\n",
      "AI: Hello, Leonardo! How can I assist you today?\n",
      "\n",
      " User: What is my name?\n",
      "AI: Your name is Leonardo! How can I assist you today?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hello! My name is Leonardo', additional_kwargs={}, response_metadata={}, id='4a173cb2-5fed-4f7b-8686-fe1305b6774c'),\n",
       "  AIMessage(content='Hello, Leonardo! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 13, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByjxQl5enFzOUrCGpS8KQhC3CCg9K', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7dd02a01-8ac6-4117-bed3-001d7c8e56f6-0', usage_metadata={'input_tokens': 13, 'output_tokens': 11, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='6496949b-2c3e-4045-ae02-fb1d7e209634'),\n",
       "  AIMessage(content='Your name is Leonardo! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 37, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByjxRcEncHCki1ajaiLO4geeST70z', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1eb1abea-b97b-4120-a63f-59ab4f680f7e-0', usage_metadata={'input_tokens': 37, 'output_tokens': 12, 'total_tokens': 49, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n Testing Conversation with Memory:\")\n",
    "\n",
    "chat_with_memory(\"Hello! My name is Leonardo\", thread_id=\"thead-1\")\n",
    "chat_with_memory(\"What is my name?\", thread_id=\"thead-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df24acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"State for our two-node agent\"\"\"\n",
    "    messages: list[BaseMessage]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "877bc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"The chatbot node decides whether to use tools or provide direct responses\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "\n",
    "    system_message = \"\"\"\n",
    "    You are a helpful assistant. You have access to web search and calculator tools.\n",
    "\n",
    "    Use the web_search tool when:\n",
    "    - Asked about current events, news, or recent information.\n",
    "    - Need to find specific facts or data.\n",
    "    - Asked about real-time information (weather, stock prices, etc.)\n",
    "\n",
    "    Use the calculator tool when:\n",
    "    - Asked to perform mathematical calculations.\n",
    "    - Need to solve math problems.\n",
    "\n",
    "    For general knowledge questions that don't require real-time data, answer directly.\n",
    "    Be helpful and conversational in your responses.\n",
    "    \"\"\"\n",
    "\n",
    "    all_messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message}\n",
    "    ] + messages\n",
    "\n",
    "    response = llm_with_tools.invoke(all_messages)\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "193010aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4dedd58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='calculator', description='Calculate mathematical expressions. Allways use this for any math calculations.', args_schema=<class 'langchain_core.utils.pydantic.calculator'>, func=<function calculator at 0x000002596E8F9440>),\n",
       " DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text'))]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1dd37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = ToolNode(tools)\n",
    "print(\"Tool node created\")\n",
    "\n",
    "def should_continue(state: AgentState) -> Literal[\"tool\", \"end\"]:\n",
    "    \"\"\"\n",
    "    Determine whether to continue to tools or end the conversation\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
